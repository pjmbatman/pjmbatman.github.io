---
title: 선형대수 핵심 개념 정리 - Mathematics for Machine Learning
date: 2025-04-30 12:00:00 +0900
categories: [Mathematics, Linear Algebra]
tags: [linear algebra, machine learning, math, study notes]
math: true
mermaid: false
---

# 📘 Chapter 2: Linear Algebra — 상세 요약 정리

《Mathematics for Machine Learning》에서 소개하는 선형대수 핵심 개념을 2.x.x 구조로 정리합니다. 정의, 수식, 예제, 기하적 직관을 포함합니다.

---

## 2.1 Systems of Linear Equations (연립 선형 방정식)

### 2.1.1 문제 구조
- m개의 식, n개의 미지수로 구성됨.
- 일반적인 형식:  
  $$
  \begin{cases}
  a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = b_1 \\
  \vdots \\
  a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = b_m
  \end{cases}
  $$
- 행렬 표현:  
  $$
  A \mathbf{x} = \mathbf{b},\quad A \in \mathbb{R}^{m \times n},\ \mathbf{x} \in \mathbb{R}^n,\ \mathbf{b} \in \mathbb{R}^m
  $$

### 2.1.2 해의 유형
- **일치 시스템** (Consistent): 적어도 하나의 해 존재
  - 유일 해: $\text{rank}(A) = n$
  - 무한 해: 자유 변수 존재
- **불일치 시스템** (Inconsistent): 해 없음 → $\mathbf{b} \notin \text{col}(A)$

### 2.1.3 기하학적 해석
- 각 식은 고차원 공간의 평면(hyperplane)
- 해 = 평면들의 교차점
- 2D 예시:  
  $$
  2x + y = 4 \quad \text{vs.}\quad -x + y = 1 \Rightarrow \text{두 직선의 교점}
  $$

---

## 2.2 Matrices (행렬)

### 2.2.1 정의와 표기
- $m \times n$ 행렬: m개의 행, n개의 열
- 표기: $A = [a_{ij}] \in \mathbb{R}^{m \times n}$

### 2.2.2 행렬 연산
- **덧셈**: 같은 크기일 때 원소별 연산
- **곱셈**:  
  $$
  (AB)_{ij} = \sum_{k=1}^{n} a_{ik}b_{kj}
  $$
- **항등 행렬** $I_n$: 대각선 1, 나머지 0 → $AI = A$

### 2.2.3 전치와 역행렬
- **전치**: $A^\top_{ij} = A_{ji}$
- **역행렬**: $A^{-1}$은 $AA^{-1} = I$
  - 조건: 정방행렬, full rank 필요
- 역행렬 존재 여부는 행렬식(determinant)과 관련 (4장에서 다룸)

### 2.2.4 스칼라곱과 성질
- 스칼라배: $\lambda A = [\lambda a_{ij}]$
- 분배법칙, 결합법칙, 결합성 모두 성립
- 곱셈은 교환법칙 불가: $AB \neq BA$

---

## 2.3 Solving Systems of Linear Equations (선형방정식 풀이)

### 2.3.1 특수 해와 일반 해
- **특수 해 (Particular solution)**: 한 가지 해 $\mathbf{x}_p$
- **일반 해 (General solution)**:  
  $$
  \mathbf{x} = \mathbf{x}_p + \sum_i \lambda_i \mathbf{v}_i \in \ker(A)
  $$

### 2.3.2 행 연산 (Row Operations)
- 행 교환, 배수 곱하기, 다른 행 더하기
- 해는 동일, 형태만 간소화

### 2.3.3 Gaussian Elimination
- 가우스 소거법으로 REF 또는 RREF 얻음
- 피벗 변수, 자유 변수 식별
- 계단형 구조 → 행의 수 = 유효 제약식 수

### 2.3.4 역행렬과의 관계
- 역행렬을 통해 해 구할 수 있는 경우: $\mathbf{x} = A^{-1}\mathbf{b}$
- 조건: 정방 + 가역

---

## 2.4 Vector Spaces (벡터 공간)

### 2.4.1 정의
- 두 연산에 대해 닫힘:
  - 벡터 덧셈 $u + v \in V$
  - 스칼라곱 $\alpha v \in V$

### 2.4.2 성질
- 항등원 존재: $\mathbf{0}$
- 역원 존재: $-v \in V$
- 덧셈/곱셈 결합/분배 성질

### 2.4.3 부분공간 (Subspaces)
- 조건:
  - 0벡터 포함
  - 선형결합에 닫힘
- 예:
  - Ax = 0의 해 공간 (null space)
  - 열공간 (column space)

---

## 2.5 Linear Independence (선형 독립성)

### 2.5.1 정의
- $\sum \lambda_i \mathbf{v}_i = 0$일 때, 모든 $\lambda_i = 0$이면 독립

### 2.5.2 선형 종속성
- 벡터 중 하나가 나머지의 선형결합이면 종속

### 2.5.3 판별 방법
- 행렬 구성 후 가우시안 소거
- 피벗 열 수 = 독립 벡터 수

---

## 2.6 Basis and Rank (기저와 랭크)

### 2.6.1 기저 (Basis)
- 정의: 선형 독립이며 공간을 생성(span)하는 벡터 집합
- 성질:
  - 최소한의 생성 집합 (minimal spanning set)
  - 최대한의 선형 독립 집합 (maximal linearly independent set)

### 2.6.2 차원 (Dimension)
- 정의: 기저의 크기 (벡터 개수)
- 예시: $\mathbb{R}^n$의 차원은 n

### 2.6.3 랭크 (Rank)
- 행렬 A의 랭크 = 열공간의 차원 = 행공간의 차원
- 계산: 행 기약 사다리꼴(RREF)에서 피벗 변수 개수
- 용도: 행렬의 독립성 측정, 시스템 해석

### 2.6.4 랭크-널리티 정리 (Rank-Nullity Theorem)
- $\text{rank}(A) + \text{nullity}(A) = n$ (A는 $m \times n$ 행렬)
- nullity = null space(kernel)의 차원

---

## 2.7 Linear Mappings (선형 사상)

### 2.7.1 정의
- $f: V \rightarrow W$가 선형이면 다음을 만족:
  - $f(x + y) = f(x) + f(y)$
  - $f(\alpha x) = \alpha f(x)$

### 2.7.2 행렬 표현
- 모든 선형 사상은 적절한 기저 하에서 행렬로 표현 가능
- $n$차원 → $m$차원 사상: $m \times n$ 행렬

### 2.7.3 핵심 부분공간
- **핵(kernel)**: $\ker(A) = \{x \in V : Ax = 0\}$
- **상(image)**: $\text{im}(A) = \{Ax : x \in V\}$

### 2.7.4 동형사상 (Isomorphism)
- 전단사 선형 사상
- 두 공간의 차원이 같을 때만 가능

---

## 2.8 Determinants (행렬식)

### 2.8.1 정의와 성질
- $n \times n$ 행렬의 스칼라 값
- 기하학적 의미: 변환 후 부피 변화 비율
- 성질:
  - $\det(AB) = \det(A)\det(B)$
  - $\det(A^T) = \det(A)$

### 2.8.2 계산 방법
- 2×2 행렬: $\det(A) = a_{11}a_{22} - a_{12}a_{21}$
- 일반 행렬: 여인수 전개 또는 가우스 소거법

### 2.8.3 응용
- 역행렬 존재 여부: $\det(A) \neq 0$ ⇔ A는 가역
- 크래머 법칙: 선형방정식 해법

---

## 2.9 Eigenvalues and Eigenvectors (고유값과 고유벡터)

### 2.9.1 정의
- 고유벡터 $v$: $Av = \lambda v$ ($v \neq 0$)
- 고유값 $\lambda$: 해당 고유벡터의 스케일 인자

### 2.9.2 특성방정식 (Characteristic Equation)
- $\det(A - \lambda I) = 0$
- n차 다항식의 근 = 고유값

### 2.9.3 고유공간 (Eigenspace)
- $\lambda$에 대한 고유공간: $E_\lambda = \{v : Av = \lambda v\}$
- 차원 = $\lambda$의 기하적 중복도

### 2.9.4 대각화 (Diagonalization)
- 조건: n개의 선형독립 고유벡터 존재
- $A = PDP^{-1}$ (D는 대각행렬)
- 응용: $A^k$ 계산 간소화, 시스템 안정성 분석

---

## 참고 문헌

- Deisenroth, M. P., Faisal, A. A., & Ong, C. S. (2020). *Mathematics for Machine Learning*. Cambridge University Press.
