---
title: "🧠 MML Chapters Review: 리뷰 및 회고"
date: 2025-04-12
tags: [MML, 리뷰, 머신러닝수학, 학습회고]
categories: [Study, Mathematics for Machine Learning]
---

# 🧠 MML Chapters 2–12: 리뷰 및 회고

> 본 리뷰는 『Mathematics for Machine Learning』 스터디의 Chapter 2부터 Chapter 12까지 학습한 내용을 정리하고, 각 장의 핵심 개념과 연결 지점을 되짚기 위한 목적으로 작성되었다.  
> 머신러닝 알고리즘의 작동 원리를 수학적으로 이해하고 해석하는 데 필요한 이론들을 체계적으로 다룬 과정이었다.

---

## 📐 Chapter 2–4: 선형 구조의 이해

- **Chapter 2: 선형대수학**  
  머신러닝의 수학적 기반으로서 벡터, 행렬, 선형방정식을 학습하였다. 벡터 공간과 기저, 랭크 개념을 통해 데이터와 모델 파라미터를 해석하는 기본기를 다졌다.

- **Chapter 3: 해석기하학**  
  벡터 간의 거리와 각도, 내적, 정사영 개념을 통해 PCA, 회귀, SVM 등에 적용되는 기하학적 직관을 수학적으로 표현할 수 있게 되었다.

- **Chapter 4: 행렬 분해**  
  고유값 분해와 특잇값 분해(SVD)를 중심으로, 데이터의 구조를 요약하고 압축하는 수단으로서의 행렬 분해 기법을 학습하였다.

---

## 🧮 Chapter 5–7: 미분과 최적화의 도구화

- **Chapter 5: 벡터 미적분학**  
  그래디언트, 야코비안, 헤시안 등의 개념을 학습하며, 신경망의 역전파와 같은 실제 학습 알고리즘의 수학적 원리를 이해하게 되었다.

- **Chapter 6: 확률과 분포**  
  확률 공간, 기댓값, 분산, 가우시안 분포 등을 통해 불확실성을 수학적으로 모델링하고, 베이즈 정리를 기반으로 한 추론의 구조를 익혔다.

- **Chapter 7: 최적화**  
  경사하강법, 라그랑주 승수법, 볼록 최적화 이론을 통해 머신러닝 학습 알고리즘의 수치 최적화 문제를 해석하고 해결하는 방법을 학습하였다.

---

## 🔗 Chapter 8–10: 모델과 데이터의 수학적 연결

- **Chapter 8: 모델과 데이터의 만남**  
  경험위험 최소화(ERM), 최대우도추정(MLE), 베이지안 추론 등의 개념을 통해 수학적으로 학습 문제를 정식화하고, 모델을 선택하는 기준을 세웠다.

- **Chapter 9: 선형 회귀**  
  지도학습의 출발점인 선형 회귀를 MLE, MAP, 베이지안 추정 관점에서 분석하였으며, 회귀 해석의 기하학적 의미도 함께 익혔다.

- **Chapter 10: 차원 축소**  
  PCA를 중심으로, 고차원 데이터를 보다 간결하고 해석 가능한 형태로 변환하는 수학적 도구들을 학습하였다.

---

## 📊 Chapter 11–12: 비지도 학습과 분류 문제

- **Chapter 11: 밀도 추정**  
  가우시안 혼합 모델(GMM)과 기대-최대화(EM) 알고리즘을 통해 비지도학습의 핵심 개념과 수학적 유도를 정리하였다.

- **Chapter 12: 분류**  
  서포트 벡터 머신(SVM)을 중심으로, 마진 최대화, 쌍대 문제, 커널 기법 등 분류기의 작동 원리를 최적화 문제로 해석할 수 있었다.

---

## ✅ 회고 및 다음 단계

본 스터디를 통해 머신러닝의 주요 알고리즘들이 어떠한 수학적 원리 위에서 작동하는지를 심층적으로 이해할 수 있었다.  
특히, 각 장의 개념들이 개별적으로 학습되기보다는 서로 유기적으로 연결되어 있다는 점에서 큰 의미가 있었다.

> 향후에는 이 수학적 기반 위에 실제 구현 경험을 더하고,  
> 논문 이해, 모델 해석, 고급 추론 기법 설계로 자연스럽게 확장해 나갈 수 있을 것이다.

감사합니다 🙏
